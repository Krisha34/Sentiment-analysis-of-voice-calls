# ğŸ™ï¸ Sentiment Analysis across Modalities

This project implements a **Sentiment Analysis system for audio recordings**, extending the ideas explored in our IEEE-published research. It supports both **live audio recording** and **audio file uploads**, and predicts:

- ğŸ“œ **Transcript** (speech-to-text)
- ğŸ™‚ **Sentiment** (positive / negative / neutral)
- ğŸ­ **Emotion** (e.g., happy, sad, angry, etc.)

---

## ğŸ“š Publications

This work builds on our research contributions:

- **Sentiment Analysis across Modalities: A Comprehensive Review of Text and Audio Approaches**  
  *IEEE, 2024*  
  [Link](https://ieeexplore.ieee.org/document/10480751)

- **Exploring Dual-Module Approaches for Sentiment Analysis in Call Recordings**  
  *IEEE, 2024*  
  [Link](https://ieeexplore.ieee.org/document/10690070)

---

## ğŸš€ Features

- ğŸ¤ **Record Audio** in-browser and send directly to the model
- ğŸ“‚ **Upload Audio Files** (`.wav`, `.mp3`, `.m4a`) for prediction
- ğŸ” **Dual-module pipeline**:
  - Automatic Speech Recognition (ASR) for transcription  
  - Sentiment + Emotion classifier using trained ML models
- ğŸŒ Web interface built with **Flask + JavaScript**
- âš¡ Supports quick deployment on Render, Railway, or GCP Cloud Run

---

## ğŸ› ï¸ Setup & Run Locally

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>/Final Project
