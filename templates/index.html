<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sentiment Analysis of Voice Calls</title>
    <style>
        /* Body Styles */
        body {
            width: 100%;
            height: 100vh;
            background-image: linear-gradient(rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.1)),
                url('https://www.nitorinfotech.com/wp-content/uploads/2023/01/Top-4-Types-of-Sentiment-Analysis-Nitor-Infotech-1.jpg');
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
            margin: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            font-family: "Times New Roman", Times, serif;
        }

        /* Header Styles */
        h1 {
            text-align: center;
            margin-top: 30px;
            color: rgb(248, 246, 250);
            font-family: "Times New Roman", Times, serif;
        }

        h2 {
            color: white;
            font-size: 20px;
            font-family: "Times New Roman", Times, serif;
        }

        /* Form Styles */
        form {
            text-align: center;
            margin-top: 20px;
        }

        input[type="file"] {
            display: inline-block;
            margin: 10px;
        }

        button {
            background: linear-gradient(to bottom, #f85757, #edad96);
            color: white;
            padding: 10px 20px;
            border: none;
            cursor: pointer;
            border-radius: 5px;
            margin: 5px;
        }

        button:hover {
            opacity: 0.8;
            background: linear-gradient(to bottom, #d38cdc, #4c195591);
        }

        /* Audio Styles */
        #audioPlayback {
            width: 100%;
            margin-top: 20px;
        }

        /* Box Styles */
        .box-container {
            display: flex;
            justify-content: center;
            width: 100%;
        }

        .box {
            width: 300px;
            background: linear-gradient(to bottom, #342138, #d8b0e2);
            margin: 20px;
            padding: 20px;
            border-radius: 10px;
            text-align: justify;
            font-size: 20px;
            border: 2px solid #ddd;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            color: #f0f0f0;
        }

        .box h2 {
            margin-top: 0;
            color: wheat;
            font-size: 25px;
        }

        .box p {
            margin-bottom: 0;
        }

        /* Modal Styles */
        .modal {
            display: none;
            position: fixed;
            z-index: 1;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            overflow: auto;
            background-color: rgb(0, 0, 0);
            background-color: rgba(0, 0, 0, 0.4);
            padding-top: 60px;
        }

        .modal-content {
            background-color: #fefefe;
            margin: 5% auto;
            padding: 20px;
            border: 1px solid #888;
            width: 80%;
        }

        .close {
            color: #aaa;
            float: right;
            font-size: 28px;
            font-weight: bold;
        }

        .close:hover,
        .close:focus {
            color: black;
            text-decoration: none;
            cursor: pointer;
        }

        /* Scrollable Transcript Box */
        #transcriptBox {
            overflow-y: auto;
            max-height: 200px;
            margin-top: 20px;
            padding: 10px;
            background-color: #f0f0f0;
            border-radius: 5px;
            border: 1px solid #ccc;
        }
    </style>
</head>

<body>
    <h1>Sentiment Analysis of Voice Calls</h1>

    <!-- Recording and Recorded Audio Playback Section\n
    <!-- Upload Audio Section (added) -->
    <div style="display: flex; justify-content: center; margin-top: 24px;">
      <div style="max-width: 560px; width: 100%; text-align: center;">
        <h2>Upload Audio</h2>
        <input id="audioFileInput" type="file" accept="audio/*" style="margin: 8px 0;" />
        <div>
          <button id="predictUploadBtn" onclick="predictUploaded()" disabled>Predict from Uploaded File</button>
        </div>
        <p style="font-size: 15px; opacity: 0.8;color: white;">Accepted: .wav, .mp3, .m4a, etc. (Browser support may vary)</p>
      </div>
    </div>
 -->
    <div style="display: flex; justify-content: space-around; width: 100%;">
        <div>
            <h2>Record Audio</h2>
            <button id="startButton" onclick="startRecording()">Start Recording</button>
            <button id="pauseButton" disabled>Pause</button>
            <button id="resumeButton" disabled>Resume</button>
            <button id="stopButton" disabled>Stop Recording</button>
        </div>
        <div>
            <h2 style="text-align: center; font-size: 20px; color: white">Recorded Audio Playback</h2>
            <audio id="recordedAudio" controls></audio>
            <a id="downloadLink" href="#" download="recorded.wav">Download</a>
        </div>
    </div>

    <!-- Predict and Transcript Buttons -->
    <div style="text-align: center; margin-top: 20px;">
        <button id="predictButton" onclick="predictSentiment()" disabled>Predict Sentiment</button>
        <button id="transcriptButton" onclick="showTranscript()" disabled>Show Transcript</button>
    </div>

    <!-- Output Section -->
    <div id="output" class="box-container">
        <div class="box" id="box1">
            <h2>Analysis Result</h2>
            <p id="transcript"> </p>
            <div id="transcriptBox" style="display: none;"></div> <!-- Hidden by default -->
            <p id="sentiment">Sentiment:</p>
        </div>
        <div class="box" id="box2">
            <h2>Emotion Analysis</h2>
            <p id="emotion">Emotion:</p>
        </div>
    </div>

    <!-- Modal for Transcript -->
    <div id="myModal" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal()">&times;</span>
            <h2>Transcript</h2>
            <div id="transcriptContent"></div>
        </div>
    </div>

    <script src="https://cdn.rawgit.com/mattdiamond/Recorderjs/08e7abd9/dist/recorder.js">
// === Upload helpers (added) ===
const fileInput = document.getElementById('audioFileInput');
const predictUploadBtn = document.getElementById('predictUploadBtn');

if (fileInput) {
  fileInput.addEventListener('change', () => {
    predictUploadBtn.disabled = !fileInput.files || fileInput.files.length === 0;
  });
}

function predictUploaded() {
  if (!fileInput || !fileInput.files || fileInput.files.length === 0) {
    alert('Please choose an audio file first.');
    return;
  }
  const file = fileInput.files[0];
  const formData = new FormData();
  formData.append('audio', file, file.name);

  const xhr = new XMLHttpRequest();
  xhr.open('POST', '/predict', true);
  xhr.onreadystatechange = function () {
    if (xhr.readyState === 4) {
      try {
        const res = JSON.parse(xhr.responseText || '{}');
        if (xhr.status === 200 && !res.error) {
          // Update transcript/sentiment/emotion boxes if present
          const transcriptBox = document.getElementById('transcriptBox');
          const sentimentBox = document.getElementById('sentimentBox');
          const emotionBox = document.getElementById('emotionBox');
          if (transcriptBox) transcriptBox.innerText = res.transcript || '(no transcript)';
          if (sentimentBox) sentimentBox.innerText = res.sentiment || '(unknown)';
          if (emotionBox) emotionBox.innerText = res.emotion || '(unknown)';
          alert('Prediction complete!');
        } else {
          alert('Error: ' + (res.error || 'Unknown error'));
        }
      } catch (e) {
        alert('Failed to parse server response.');
      }
    }
  };
  xhr.send(formData);
}

</script>
    <script>
        let audioContext;
        let recorder;
        let recordedBlob; // Variable to store the recorded audio blob

        const startButton = document.getElementById('startButton');
        const pauseButton = document.getElementById('pauseButton');
        const resumeButton = document.getElementById('resumeButton');
        const stopButton = document.getElementById('stopButton');
        const predictButton = document.getElementById('predictButton');
        const transcriptButton = document.getElementById('transcriptButton');
        const transcriptBox = document.getElementById('transcriptBox');
        const modal = document.getElementById("myModal");
        const transcriptContent = document.getElementById("transcriptContent");

        startButton.addEventListener('click', startRecording);
        pauseButton.addEventListener('click', pauseRecording);
        resumeButton.addEventListener('click', resumeRecording);
        stopButton.addEventListener('click', stopRecording);
        predictButton.addEventListener('click', predictSentiment);
        transcriptButton.addEventListener('click', showTranscript);

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then((stream) => {
                    audioContext = new(window.AudioContext || window.webkitAudioContext)();
                    const input = audioContext.createMediaStreamSource(stream);
                    recorder = new Recorder(input);
                    recorder.record();

                    startButton.disabled = true;
                    pauseButton.disabled = false;
                    resumeButton.disabled = true;
                    stopButton.disabled = false;
                    predictButton.disabled = true;
                })
                .catch((err) => {
                    console.error('Error accessing microphone:', err);
                });
        }

        function pauseRecording() {
            recorder.pause();

            pauseButton.disabled = true;
            resumeButton.disabled = false;
        }

        function resumeRecording() {
            recorder.resume();

            pauseButton.disabled = false;
            resumeButton.disabled = true;
        }

        function stopRecording() {
            recorder.stop();
            audioContext.close();

            recorder.exportWAV((blob) => {
                recordedBlob = blob; // Store the recorded blob for later use
                const url = URL.createObjectURL(blob);
                const recordedAudioElement = document.getElementById('recordedAudio');
                const downloadLink = document.getElementById('downloadLink');

                recordedAudioElement.src = url;
                recordedAudioElement.controls = true;
                downloadLink.href = url;

                startButton.disabled = false;
                pauseButton.disabled = true;
                resumeButton.disabled = true;
                stopButton.disabled = true;
                predictButton.disabled = false; // Enable the Predict button after recording
                transcriptButton.disabled = false; // Enable the Transcript button after recording
            });
        }

        function predictSentiment() {
            // Call the uploadAudio function with the recorded audio blob
            uploadAudio(recordedBlob);
        }

        function uploadAudio(blob) {
            var formData = new FormData();
            formData.append('audio', blob, 'recorded.wav');

            var xhr = new XMLHttpRequest();
            xhr.open('POST', '/predict', true);

            xhr.onload = function() {
                if (xhr.status === 200) {
                    var response = JSON.parse(xhr.responseText);
                    document.getElementById('transcript').textContent = "Transcript:";
                    document.getElementById('sentiment').textContent = "Sentiment: " + response.sentiment;
                    document.getElementById('emotion').textContent = "Emotion: " + response.emotion;
                    transcriptBox.innerText = response.transcript;
                } else {
                    console.error('Error:', xhr.statusText);
                }
            };

            xhr.onerror = function() {
                console.error('Error:', xhr.statusText);
            };

            xhr.send(formData);
        }

        function showTranscript() {
            modal.style.display = "block";
            transcriptContent.innerText = transcriptBox.innerText;
        }

        function closeModal() {
            modal.style.display = "none";
        }
    </script>
</body>

</html>